{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Copy of Xception.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLtWaKgdxPWI"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dVAqoqSxD7q"
      },
      "source": [
        "# Run if you are using google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csZ0XAgAxPWM"
      },
      "source": [
        "def get_nb_files(directory):\n",
        "    \"\"\"Get number of files by searching directory recursively\"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        print ('No directory')\n",
        "        return 0\n",
        "    cnt = 0\n",
        "    for r, dirs, files in os.walk(directory):\n",
        "        for dr in dirs:\n",
        "              cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "    return cnt\n",
        "\n",
        "def add_new_last_layer(base_model, nb_classes):\n",
        "    \"\"\"Add last layer to the convnet\n",
        "    Arguments:\n",
        "        base_model: keras model (without a top layer)\n",
        "        nb_classes: number of classes\n",
        "    Returns:\n",
        "        new keras model with last layer\n",
        "    \"\"\"\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    \n",
        "    predictions = Dense(nb_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def setup_to_transfer_learn(model, args):\n",
        "    \"\"\"Freezes all layers but the last one and compiles the model\"\"\"\n",
        "\n",
        "    for layer in model.layers[:-1]:\n",
        "      layer.trainable = False \n",
        "\n",
        "    model.layers[-1].trainable=True\n",
        "    opt = Nadam(lr=args.lr)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def setup_to_finetune(model, args, not_trainable):\n",
        "    \"\"\"Freezes the first not_trainable layers, and unfreezes the rest\n",
        "    Arguments:\n",
        "        model: keras model\n",
        "        not_trainable: number of not trainable layers\n",
        "    \"\"\"\n",
        "    \n",
        "    #Set the layers [0:not_trainable] to not trainable. Set the layers [not_trainable:] to trainable\n",
        "    for layer in model.layers[0:not_trainable]:\n",
        "      layer.trainable = False\n",
        "      \n",
        "    for layer in model.layers[not_trainable:]:\n",
        "      layer.trainable = True\n",
        "\n",
        "    opt = Nadam(lr=args.lr)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7ikt-GBxPWN"
      },
      "source": [
        "\n",
        "### Plot results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gcu0Gl27xPWN"
      },
      "source": [
        "def unpack_history(history, old_history = None):\n",
        "    if old_history is None:\n",
        "        new_history = {\n",
        "            'accuracy' : [],\n",
        "            'val_accuracy' : [],\n",
        "            'loss' : [],\n",
        "            'val_loss' : [],\n",
        "        }  \n",
        "    else:\n",
        "        new_history = old_history\n",
        "    new_history['accuracy'] += history.history['accuracy']\n",
        "    new_history['val_accuracy'] += history.history['val_accuracy']\n",
        "    new_history['loss'] += history.history['loss']\n",
        "    new_history['val_loss'] += history.history['val_loss']\n",
        "    return new_history\n",
        "\n",
        "def plot_history(training_history):\n",
        "    acc = training_history['accuracy']\n",
        "    val_acc = training_history['val_accuracy']\n",
        "    loss = training_history['loss']\n",
        "    val_loss = training_history['val_loss']\n",
        "    epochs = np.arange(len(acc)) + 1\n",
        "    \n",
        "    fig = plt.figure(figsize=(12, 4))\n",
        "\n",
        "    ax1 = fig.add_subplot(121)    \n",
        "    ax1.plot(epochs, loss, c='g', label='Train')\n",
        "    ax1.plot(epochs, val_loss, c='r', label='Valid')\n",
        "    ax1.set_title('Loss')\n",
        "    ax1.legend(loc='lower left');\n",
        "    ax1.grid(True)\n",
        "    \n",
        "    ax2 = fig.add_subplot(122)    \n",
        "    ax2.plot(epochs, acc, c='g', label='Train')\n",
        "    ax2.plot(epochs, val_acc, c='r', label='Valid')\n",
        "    ax2.set_title('Accuracy')\n",
        "    #ax2.legend(loc='upper left');\n",
        "    ax2.grid(True)\n",
        "        \n",
        "    plt.show()    \n",
        "\n",
        "\n",
        "def process_and_display(history, old_history = None):\n",
        "    new_history = unpack_history(history, old_history)\n",
        "    plot_history(new_history)\n",
        "    return new_history\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIYqpeLlxPWO"
      },
      "source": [
        "### Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27_24vQMxPWO"
      },
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.im_width, self.im_height = 299, 299 #fixed size for Xception\n",
        "        self.lr = 0.001\n",
        "        self.batch_size = 64\n",
        "        \n",
        "        local_folder = '/content/drive/My Drive/Chess-joint'\n",
        "        self.train_dir = os.path.join(local_folder, 'train/')\n",
        "        self.valid_dir = os.path.join(local_folder, 'valid/')\n",
        "        self.test_dir = os.path.join(local_folder, 'test/')\n",
        "            \n",
        "args = Args()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTivQAhmxPWO"
      },
      "source": [
        "### Global variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGeRrcsvxPWP"
      },
      "source": [
        "nb_train_samples = get_nb_files(args.train_dir)\n",
        "classes = glob.glob(args.train_dir + \"/*\")\n",
        "classes = [x.split('/')[-1] for x in classes]\n",
        "classes.sort()\n",
        "nb_classes = len(classes)\n",
        "nb_valid_samples = get_nb_files(args.valid_dir)\n",
        "\n",
        "train_steps = int(nb_train_samples / args.batch_size)\n",
        "valid_steps = int (nb_valid_samples / args.batch_size)\n",
        "\n",
        "print ('Train dataset contains {} samples ({} steps / epoch)'.format(nb_train_samples, train_steps))\n",
        "print ('Valid dataset contains {} samples ({} steps / epoch)'.format(nb_valid_samples, valid_steps))\n",
        "print ('Dataset contains {} classes ({}).'.format(nb_classes, classes))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRa5FjkHxPWP"
      },
      "source": [
        "### Generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1fRcyIqxPWQ"
      },
      "source": [
        "# add data augmentation to the generator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    brightness_range=(0.5, 1.5)\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    args.train_dir,\n",
        "    target_size=(args.im_width, args.im_height),\n",
        "    batch_size=args.batch_size,\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    args.valid_dir,\n",
        "    target_size=(args.im_width, args.im_height),\n",
        "    batch_size=args.batch_size,\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    args.test_dir,\n",
        "    target_size=(args.im_width, args.im_height),\n",
        "    batch_size=args.batch_size\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRfF5R9MxPWR"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wiPWrBvxPWR"
      },
      "source": [
        "model = Xception(weights='imagenet', include_top=False)\n",
        "model = add_new_last_layer(model, nb_classes)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX41-YUPxPWS"
      },
      "source": [
        "### Transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1FHTyr9xPWS"
      },
      "source": [
        "setup_to_transfer_learn(model, args)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 5,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = valid_steps,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u2QJja--gEs"
      },
      "source": [
        "tl_history = process_and_display(history)\n",
        "model.save_weights('checkpoints/transfer_learning')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJYC8E99xPWS"
      },
      "source": [
        "### Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAi_OYZlaRE6"
      },
      "source": [
        "len(model.layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC55raTpxPWT"
      },
      "source": [
        "model.layers[126].get_config()['name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JETkzkH0xPWT"
      },
      "source": [
        "setup_to_finetune(model, args, not_trainable=126)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 2,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = valid_steps,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HegETo1O-gEt"
      },
      "source": [
        "ft126_history = process_and_display(history, tl_history)\n",
        "model.save_weights('checkpoints/fine_tuning_126')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzc7Fm0T-gEt"
      },
      "source": [
        "model.layers[116].get_config()['name']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJpl4j19-gEt"
      },
      "source": [
        "setup_to_finetune(model, args, not_trainable=116)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 2,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = valid_steps,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoNIZBGp-gEt"
      },
      "source": [
        "ft116_history = process_and_display(history, tl_history)\n",
        "model.save_weights('checkpoints/fine_tuning_116')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2mQbLjQ-gEu"
      },
      "source": [
        "setup_to_finetune(model, args, not_trainable=106)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 2,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = valid_steps,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MwrXXmj-gEu"
      },
      "source": [
        "ft106_history = process_and_display(history, tl_history)\n",
        "model.save_weights('checkpoints/fine_tuning_106')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krzW0MSVgHcU"
      },
      "source": [
        "setup_to_finetune(model, args, not_trainable=96)\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_steps,\n",
        "    epochs = 2,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps = valid_steps,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEYtRMb0gH-U"
      },
      "source": [
        "ft96_history = process_and_display(history, tl_history)\n",
        "model.save_weights('checkpoints/fine_tuning_96')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuPWbYlYxPWT"
      },
      "source": [
        "# Save the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hl0_G2UxPWT"
      },
      "source": [
        "model.load_weights('checkpoints/fine_tuning_96')\n",
        "model.save('checkpoints/final')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U6BCXTexPWU"
      },
      "source": [
        "# TEST SCORES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy3Kb8iWxPWU"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('checkpoints/final')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deicCzzuxPWU"
      },
      "source": [
        "nb_test_samples = get_nb_files(args.test_dir)\n",
        "test_steps = int (nb_test_samples / args.batch_size)\n",
        "model.evaluate(test_generator, steps=test_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBm6F5edxPWU"
      },
      "source": [
        "# Sample usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQDQknk7-gEw"
      },
      "source": [
        "def predict(model, filepath):\n",
        "  classes = ['Bishop', 'King', 'Knight', 'Pawn', 'Queen', 'Rook']\n",
        "  img = image.load_img(filepath, target_size=(299, 299))\n",
        "\n",
        "  img_array = image.img_to_array(img)\n",
        "  print(img_array.shape)\n",
        "  img_batch = np.expand_dims(img, axis=0)\n",
        "  print(img_batch.shape)\n",
        "  img_preprocessed = preprocess_input(img_batch)\n",
        "\n",
        "  prediction = model.predict(img_preprocessed)\n",
        "  print(prediction)\n",
        "\n",
        "  img_graph = plt.figure(2)\n",
        "  plt.imshow(img)\n",
        "\n",
        "  pred_graph = plt.figure(1)\n",
        "  plt.bar(classes, prediction[0])\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz3iTj24OZmk"
      },
      "source": [
        "file = '/content/drive/My Drive/Chessman-image-test/king.jpg'\n",
        "predict(model, file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}